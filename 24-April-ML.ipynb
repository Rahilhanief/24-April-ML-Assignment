{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94c2ab8-6378-46ec-b791-2a853a9ea48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis paper introduces a Projected Principal Component Analysis (Projected-PCA), \\nwhich employees principal component analysis to the projected (smoothed) data matrix onto a given linear space spanned by covariates.\\nWhen it applies to high-dimensional factor analysis, the projection removes noise components.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 1 :\n",
    "\"\"\"\n",
    "This paper introduces a Projected Principal Component Analysis (Projected-PCA), \n",
    "which employees principal component analysis to the projected (smoothed) data matrix\n",
    "onto a given linear space spanned by covariates.\n",
    "When it applies to high-dimensional factor analysis, the projection removes noise components.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5b6dc0-072b-43cd-b3e2-a1304b3095f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIf our sole intention of doing PCA is for data visualization, the best number of components is 2 or 3.\\nIf we really want to reduce the size of the dataset, the best number of principal components is much \\nless than the number of variables in the original dataset.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 2 :\n",
    "\"\"\"\n",
    "If our sole intention of doing PCA is for data visualization, the best number of components is 2 or 3.\n",
    "If we really want to reduce the size of the dataset, the best number of principal components is much \n",
    "less than the number of variables in the original dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781d2701-bd56-4ccb-9416-4f4815dc6a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA is simply described as “diagonalizing the covariance matrix”.\\nWhat does diagonalizing a matrix mean in this context? It simply means that we need to find a \\nnon-trivial linear combination of our original variables such that the covariance matrix is diagonal.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 3 :\n",
    "\"\"\"\n",
    "PCA is simply described as “diagonalizing the covariance matrix”.\n",
    "What does diagonalizing a matrix mean in this context? It simply means that we need to find a \n",
    "non-trivial linear combination of our original variables such that the covariance matrix is diagonal.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bedec3f-87c4-4f2f-a3cd-2898b68f3005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSo, the idea is 10-dimensional data gives you 10 principal components, but PCA tries to put maximum \\npossible information in the first component, then maximum remaining information in the second and so on.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 4 :\n",
    "\"\"\"\n",
    "So, the idea is 10-dimensional data gives you 10 principal components, but PCA tries to put maximum \n",
    "possible information in the first component, then maximum remaining information in the second and so on.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb65c1bc-72c6-4619-847e-fb51928b7abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA can be used to identify the most important features in a dataset, which can be used to build predictive models. \\nVisualization: PCA can be used to visualize high-dimensional data in two or three dimensions, \\nmaking it easier to understand and interpret.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q  No. 5 :\n",
    "\"\"\"\n",
    "PCA can be used to identify the most important features in a dataset, which can be used to build predictive models. \n",
    "Visualization: PCA can be used to visualize high-dimensional data in two or three dimensions, \n",
    "making it easier to understand and interpret.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f25c25a7-437a-4298-8660-320df1cd9de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA is used to visualize multidimensional data.\\nIt is used to reduce the number of dimensions in healthcare data.\\nPCA can help resize an image.\\nIt can be used in finance to analyze stock data and forecast returns.\\nPCA helps to find patterns in the high-dimensional datasets.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 6 :\n",
    "\"\"\"\n",
    "PCA is used to visualize multidimensional data.\n",
    "It is used to reduce the number of dimensions in healthcare data.\n",
    "PCA can help resize an image.\n",
    "It can be used in finance to analyze stock data and forecast returns.\n",
    "PCA helps to find patterns in the high-dimensional datasets.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8910b1bc-8962-4f22-8c33-cddbad3f1051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn general, the larger the variance explained by a principal component, the more important that component is.\\nPCA is a technique used to reduce the dimensionality of data. \\nIt does this by finding the directions of maximum variance in the data and projecting the data onto those directions.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q no. 7 :\n",
    "\"\"\"\n",
    "In general, the larger the variance explained by a principal component, the more important that component is.\n",
    "PCA is a technique used to reduce the dimensionality of data. \n",
    "It does this by finding the directions of maximum variance in the data and projecting the data onto those directions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06d43ba1-54e5-4b88-ba4a-b94ad34f7461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA works by finding the directions of maximum variance in the data set and projecting the data onto these directions.\\nThe principal components are ordered by the amount of variance they explain and are used for feature selection,\\ndata compression, clustering, and classification.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 8 :\n",
    "\"\"\"\n",
    "PCA works by finding the directions of maximum variance in the data set and projecting the data onto these directions.\n",
    "The principal components are ordered by the amount of variance they explain and are used for feature selection,\n",
    "data compression, clustering, and classification.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2642ce3d-f24f-40e2-a1b1-2c5b8ceb9491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA is a linear dimension-reduction technique that finds new axes that maximize the variance in the data. \\nThe first of these principal axes maximizes the most variance, followed by the second, and the third, and so on,\\nwhich are all orthogonal to the previously computed axes.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 9 :\n",
    "\"\"\"\n",
    "PCA is a linear dimension-reduction technique that finds new axes that maximize the variance in the data. \n",
    "The first of these principal axes maximizes the most variance, followed by the second, and the third, and so on,\n",
    "which are all orthogonal to the previously computed axes.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
